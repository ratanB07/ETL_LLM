<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>GENFLOW - LLM-based Code Generation</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <style>
        :root {
            --primary: #4f46e5;
            --primary-dark: #4338ca;
            --primary-light: #6366f1;
            --secondary: #10b981;
            --danger: #ef4444;
            --warning: #f59e0b;
            --info: #3b82f6;
            --dark: #1e293b;
            --light: #f8fafc;
            --gray: #64748b;
            --gray-light: #e2e8f0;
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
            font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
        }

        body {
            background-color: #f5f7fa;
            color: var(--dark);
        }

        .header {
            background: linear-gradient(135deg, var(--primary) 0%, var(--primary-dark) 100%);
            color: white;
            padding: 16px 24px;
            display: flex;
            align-items: center;
            justify-content: space-between;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        }

        .logo {
            display: flex;
            align-items: center;
            gap: 12px;
        }

        .logo-text {
            font-weight: 700;
            font-size: 22px;
            letter-spacing: 0.5px;
        }

        .main-container {
            max-width: 1200px;
            margin: 24px auto;
            padding: 0 20px;
        }

        .panel {
            background-color: white;
            border-radius: 12px;
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.05);
            margin-bottom: 24px;
            overflow: hidden;
        }

        .panel-header {
            padding: 16px 24px;
            border-bottom: 1px solid var(--gray-light);
            display: flex;
            justify-content: space-between;
            align-items: center;
        }

        .panel-title {
            font-size: 18px;
            font-weight: 600;
            color: var(--dark);
            display: flex;
            align-items: center;
            gap: 10px;
        }

        .panel-body {
            padding: 20px;
        }

        .code-container {
            position: relative;
            margin-bottom: 20px;
        }

        .code-header {
            background-color: var(--dark);
            color: white;
            padding: 8px 16px;
            border-top-left-radius: 6px;
            border-top-right-radius: 6px;
            display: flex;
            justify-content: space-between;
            align-items: center;
        }

        .code-content {
            background-color: #1e1e1e;
            color: #d4d4d4;
            padding: 16px;
            border-bottom-left-radius: 6px;
            border-bottom-right-radius: 6px;
            overflow-x: auto;
            font-family: 'Courier New', Courier, monospace;
            font-size: 14px;
            line-height: 1.5;
            tab-size: 4;
        }

        .copy-btn {
            background-color: rgba(255, 255, 255, 0.1);
            color: white;
            border: none;
            padding: 4px 8px;
            border-radius: 4px;
            cursor: pointer;
            font-size: 12px;
            transition: background-color 0.2s;
        }

        .copy-btn:hover {
            background-color: rgba(255, 255, 255, 0.2);
        }

        .tabs {
            display: flex;
            border-bottom: 1px solid var(--gray-light);
            margin-bottom: 16px;
        }

        .tab {
            padding: 12px 24px;
            cursor: pointer;
            font-weight: 500;
            color: var(--gray);
            border-bottom: 3px solid transparent;
            transition: all 0.2s;
        }

        .tab.active {
            color: var(--primary);
            border-bottom-color: var(--primary);
        }

        .tab:hover:not(.active) {
            color: var(--dark);
        }

        .tab-content {
            display: none;
        }

        .tab-content.active {
            display: block;
        }

        .btn {
            padding: 10px 16px;
            border-radius: 6px;
            font-weight: 500;
            cursor: pointer;
            transition: all 0.2s;
            border: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
        }

        .btn-primary {
            background: linear-gradient(135deg, var(--primary) 0%, var(--primary-dark) 100%);
            color: white;
        }

        .btn-primary:hover {
            transform: translateY(-1px);
            box-shadow: 0 4px 8px rgba(79, 70, 229, 0.3);
        }

        .btn-secondary {
            background-color: white;
            color: var(--primary);
            border: 1px solid var(--gray-light);
        }

        .btn-secondary:hover {
            background-color: var(--gray-light);
        }

        .status-indicator {
            display: inline-flex;
            align-items: center;
            gap: 8px;
            padding: 6px 12px;
            border-radius: 20px;
            font-size: 14px;
            font-weight: 500;
            background-color: var(--light);
        }

        .status-dot {
            width: 10px;
            height: 10px;
            border-radius: 50%;
        }

        .status-processing {
            background-color: var(--warning);
            animation: pulse 1.5s infinite;
        }

        .status-success {
            background-color: var(--secondary);
        }

        .explanation {
            background-color: var(--light);
            padding: 16px;
            border-radius: 8px;
            margin-bottom: 16px;
            border-left: 4px solid var(--primary);
        }

        .explanation h3 {
            margin-bottom: 8px;
            color: var(--primary);
        }

        .explanation p {
            margin-bottom: 8px;
            line-height: 1.6;
        }

        @keyframes pulse {
            0% { opacity: 1; }
            50% { opacity: 0.5; }
            100% { opacity: 1; }
        }

        .loading-spinner {
            display: inline-block;
            width: 20px;
            height: 20px;
            border: 3px solid rgba(79, 70, 229, 0.3);
            border-radius: 50%;
            border-top-color: var(--primary);
            animation: spin 1s ease-in-out infinite;
        }

        @keyframes spin {
            to { transform: rotate(360deg); }
        }

        .grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 20px;
            margin-bottom: 20px;
        }

        .card {
            background-color: white;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.05);
            padding: 16px;
            border: 1px solid var(--gray-light);
        }

        .card h3 {
            margin-bottom: 12px;
            color: var(--primary);
        }

        .card p {
            color: var(--gray);
            font-size: 14px;
            line-height: 1.5;
        }

        .syntax-highlight {
            color: #569cd6;
        }

        .syntax-string {
            color: #ce9178;
        }

        .syntax-comment {
            color: #6a9955;
        }

        .syntax-keyword {
            color: #c586c0;
        }

        .syntax-function {
            color: #dcdcaa;
        }
    </style>
</head>
<body>
    <div class="header">
        <div class="logo">
            <div class="logo-text">GENFLOW - LLM Code Generation</div>
        </div>
        <div class="status-indicator">
            <div class="status-dot status-success"></div>
            <span>Connected to AI Service</span>
        </div>
    </div>

    <div class="main-container">
        <div class="panel">
            <div class="panel-header">
                <div class="panel-title">
                    <i class="fas fa-robot"></i>
                    LLM-based ETL Code Generation
                </div>
            </div>
            <div class="panel-body">
                <div class="explanation">
                    <h3>AI-Powered ETL Code Generation</h3>
                    <p>Our advanced LLM analyzes your data structure and generates optimized ETL code tailored to your specific needs. The AI considers best practices for data quality, performance, and maintainability.</p>
                    <p>Below you'll find automatically generated code recipes for your data pipeline. You can customize the parameters or regenerate code with different approaches.</p>
                </div>

                <div class="tabs">
                    <div class="tab active" onclick="setActiveTab(this, 'python')">Python</div>
                    <div class="tab" onclick="setActiveTab(this, 'pyspark')">PySpark</div>
                    <div class="tab" onclick="setActiveTab(this, 'sql')">SQL</div>
                    <div class="tab" onclick="setActiveTab(this, 'scala')">Scala</div>
                </div>

                <div id="python" class="tab-content active">
                    <div class="code-container">
                        <div class="code-header">
                            <span>Python ETL Pipeline</span>
                            <button class="copy-btn" onclick="copyCode('python-code')">
                                <i class="fas fa-copy"></i> Copy
                            </button>
                        </div>
                        <pre id="python-code" class="code-content"><code># Import required libraries
import pandas as pd
import numpy as np
from datetime import datetime

<span class="syntax-comment"># Load source data</span>
<span class="syntax-keyword">def</span> <span class="syntax-function">load_data</span>(file_path):
    <span class="syntax-keyword">try</span>:
        <span class="syntax-keyword">if</span> file_path.endswith(<span class="syntax-string">'.csv'</span>):
            df = pd.read_csv(file_path)
        <span class="syntax-keyword">elif</span> file_path.endswith(<span class="syntax-string">'.xlsx'</span>):
            df = pd.read_excel(file_path)
        <span class="syntax-keyword">else</span>:
            <span class="syntax-keyword">raise</span> ValueError(<span class="syntax-string">"Unsupported file format"</span>)
        
        <span class="syntax-comment"># Basic data quality checks</span>
        <span class="syntax-keyword">if</span> df.empty:
            <span class="syntax-keyword">raise</span> ValueError(<span class="syntax-string">"Empty dataframe loaded"</span>)
            
        <span class="syntax-keyword">return</span> df
        
    <span class="syntax-keyword">except</span> Exception <span class="syntax-keyword">as</span> e:
        print(<span class="syntax-string">f"Error loading data: {str(e)}"</span>)
        <span class="syntax-keyword">raise</span>

<span class="syntax-comment"># Data transformation pipeline</span>
<span class="syntax-keyword">def</span> <span class="syntax-function">transform_data</span>(df):
    <span class="syntax-comment"># Handle missing values</span>
    df = df.fillna({
        <span class="syntax-string">'numeric_columns'</span>: df.select_dtypes(include=np.number).mean(),
        <span class="syntax-string">'text_columns'</span>: <span class="syntax-string">'Unknown'</span>,
        <span class="syntax-string">'date_columns'</span>: datetime.now().date()
    })
    
    <span class="syntax-comment"># Standardize text data</span>
    text_cols = df.select_dtypes(include=<span class="syntax-string">'object'</span>).columns
    <span class="syntax-keyword">for</span> col <span class="syntax-keyword">in</span> text_cols:
        df[col] = df[col].str.strip().str.title()
    
    <span class="syntax-comment"># Convert date columns</span>
    <span class="syntax-keyword">for</span> col <span class="syntax-keyword">in</span> df.select_dtypes(include=<span class="syntax-string">'datetime'</span>).columns:
        df[col] = pd.to_datetime(df[col])
    
    <span class="syntax-comment"># Add derived columns</span>
    df[<span class="syntax-string">'processing_date'</span>] = datetime.now().date()
    
    <span class="syntax-keyword">return</span> df

<span class="syntax-comment"># Main ETL execution</span>
<span class="syntax-keyword">if</span> __name__ == <span class="syntax-string">"__main__"</span>:
    <span class="syntax-keyword">try</span>:
        <span class="syntax-comment"># Load configuration</span>
        input_file = <span class="syntax-string">"data/input_dataset.csv"</span>
        output_file = <span class="syntax-string">"data/processed_data.parquet"</span>
        
        <span class="syntax-comment"># Execute pipeline</span>
        raw_data = load_data(input_file)
        processed_data = transform_data(raw_data)
        
        <span class="syntax-comment"># Save results</span>
        processed_data.to_parquet(output_file)
        print(<span class="syntax-string">f"Successfully processed {len(processed_data)} records"</span>)
        
    <span class="syntax-keyword">except</span> Exception <span class="syntax-keyword">as</span> e:
        print(<span class="syntax-string">f"ETL pipeline failed: {str(e)}"</span>)</code></pre>
                    </div>

                    <div class="grid">
                        <div class="card">
                            <h3>Optimization Tips</h3>
                            <p>• Use <code>dask</code> for larger-than-memory datasets</p>
                            <p>• Implement chunk processing for very large files</p>
                            <p>• Consider <code>polars</code> for faster DataFrame operations</p>
                        </div>
                        <div class="card">
                            <h3>Customization Options</h3>
                            <p>• Adjust missing value handling strategy</p>
                            <p>• Add specific data validation rules</p>
                            <p>• Modify date/time formatting</p>
                        </div>
                        <div class="card">
                            <h3>Quality Checks</h3>
                            <p>• Row count validation</p>
                            <p>• Null percentage thresholds</p>
                            <p>• Data type consistency</p>
                        </div>
                    </div>
                </div>

                <div id="pyspark" class="tab-content">
                    <div class="code-container">
                        <div class="code-header">
                            <span>PySpark ETL Pipeline</span>
                            <button class="copy-btn" onclick="copyCode('pyspark-code')">
                                <i class="fas fa-copy"></i> Copy
                            </button>
                        </div>
                        <pre id="pyspark-code" class="code-content"><code><span class="syntax-keyword">from</span> pyspark.sql <span class="syntax-keyword">import</span> SparkSession
<span class="syntax-keyword">from</span> pyspark.sql.functions <span class="syntax-keyword">import</span> *
<span class="syntax-keyword">from</span> pyspark.sql.types <span class="syntax-keyword">import</span> *

<span class="syntax-comment"># Initialize Spark session</span>
spark = SparkSession.builder \
    .appName(<span class="syntax-string">"ETLPipeline"</span>) \
    .config(<span class="syntax-string">"spark.sql.shuffle.partitions"</span>, <span class="syntax-string">"8"</span>) \
    .getOrCreate()

<span class="syntax-comment"># Load data function</span>
<span class="syntax-keyword">def</span> <span class="syntax-function">load_data</span>(path, file_type=<span class="syntax-string">"csv"</span>):
    <span class="syntax-keyword">try</span>:
        <span class="syntax-keyword">if</span> file_type == <span class="syntax-string">"csv"</span>:
            df = spark.read \
                .option(<span class="syntax-string">"header"</span>, <span class="syntax-string">"true"</span>) \
                .option(<span class="syntax-string">"inferSchema"</span>, <span class="syntax-string">"true"</span>) \
                .csv(path)
        <span class="syntax-keyword">elif</span> file_type == <span class="syntax-string">"parquet"</span>:
            df = spark.read.parquet(path)
        <span class="syntax-keyword">else</span>:
            <span class="syntax-keyword">raise</span> ValueError(<span class="syntax-string">f"Unsupported file type: {file_type}"</span>)
            
        <span class="syntax-keyword">if</span> df.rdd.isEmpty():
            <span class="syntax-keyword">raise</span> ValueError(<span class="syntax-string">"Empty dataframe loaded"</span>)
            
        <span class="syntax-keyword">return</span> df
        
    <span class="syntax-keyword">except</span> Exception <span class="syntax-keyword">as</span> e:
        print(<span class="syntax-string">f"Error loading data: {str(e)}"</span>)
        spark.stop()
        <span class="syntax-keyword">raise</span>

<span class="syntax-comment"># Transformation function</span>
<span class="syntax-keyword">def</span> <span class="syntax-function">transform_data</span>(df):
    <span class="syntax-comment"># Clean column names</span>
    <span class="syntax-keyword">for</span> col <span class="syntax-keyword">in</span> df.columns:
        df = df.withColumnRenamed(col, col.replace(<span class="syntax-string">" "</span>, <span class="syntax-string">"_"</span>).lower())
    
    <span class="syntax-comment"># Handle missing values</span>
    df = df.fillna({
        <span class="syntax-string">"numeric_columns"</span>: 0,
        <span class="syntax-string">"string_columns"</span>: <span class="syntax-string">"Unknown"</span>,
        <span class="syntax-string">"date_columns"</span>: current_date()
    })
    
    <span class="syntax-comment"># Standardize text</span>
    text_cols = [f.name <span class="syntax-keyword">for</span> f <span class="syntax-keyword">in</span> df.schema <span class="syntax-keyword">if</span> isinstance(f.dataType, StringType)]
    <span class="syntax-keyword">for</span> col <span class="syntax-keyword">in</span> text_cols:
        df = df.withColumn(col, trim(initcap(col(col))))
    
    <span class="syntax-comment"># Add processing metadata</span>
    df = df.withColumn(<span class="syntax-string">"processing_timestamp"</span>, current_timestamp())
    
    <span class="syntax-keyword">return</span> df

<span class="syntax-comment"># Main execution</span>
<span class="syntax-keyword">if</span> __name__ == <span class="syntax-string">"__main__"</span>:
    <span class="syntax-keyword">try</span>:
        <span class="syntax-comment"># Configuration</span>
        input_path = <span class="syntax-string">"s3://data-lake/raw/input_data/"</span>
        output_path = <span class="syntax-string">"s3://data-lake/processed/output/"</span>
        
        <span class="syntax-comment"># Execute pipeline</span>
        raw_df = load_data(input_path, <span class="syntax-string">"csv"</span>)
        processed_df = transform_data(raw_df)
        
        <span class="syntax-comment"># Write output</span>
        processed_df.write \
            .mode(<span class="syntax-string">"overwrite"</span>) \
            .parquet(output_path)
            
        print(<span class="syntax-string">f"Successfully processed {processed_df.count()} records"</span>)
        
    <span class="syntax-keyword">except</span> Exception <span class="syntax-keyword">as</span> e:
        print(<span class="syntax-string">f"ETL failed: {str(e)}"</span>)
    <span class="syntax-keyword">finally</span>:
        spark.stop()</code></pre>
                    </div>

                    <div class="grid">
                        <div class="card">
                            <h3>Cluster Optimization</h3>
                            <p>• Adjust partition count based on data size</p>
                            <p>• Use broadcast joins for small dimension tables</p>
                            <p>• Cache frequently used DataFrames</p>
                        </div>
                        <div class="card">
                            <h3>Advanced Features</h3>
                            <p>• Delta Lake for ACID transactions</p>
                            <p>• Structured Streaming for real-time</p>
                            <p>• MLlib integration for transformations</p>
                        </div>
                        <div class="card">
                            <h3>Performance</h3>
                            <p>• Partition by date columns</p>
                            <p>• Use Parquet/ZSTD compression</p>
                            <p>• Optimize shuffle operations</p>
                        </div>
                    </div>
                </div>

                <div id="sql" class="tab-content">
                    <div class="code-container">
                        <div class="code-header">
                            <span>SQL ETL Script</span>
                            <button class="copy-btn" onclick="copyCode('sql-code')">
                                <i class="fas fa-copy"></i> Copy
                            </button>
                        </div>
                        <pre id="sql-code" class="code-content"><code><span class="syntax-comment">-- Create staging table for raw data</span>
<span class="syntax-keyword">CREATE</span> <span class="syntax-keyword">TABLE</span> IF <span class="syntax-keyword">NOT</span> <span class="syntax-keyword">EXISTS</span> staging.raw_data (
    customer_id <span class="syntax-highlight">INT</span>,
    customer_name <span class="syntax-highlight">VARCHAR</span>(<span class="syntax-highlight">100</span>),
    email <span class="syntax-highlight">VARCHAR</span>(<span class="syntax-highlight">255</span>),
    signup_date <span class="syntax-highlight">DATE</span>,
    last_purchase <span class="syntax-highlight">TIMESTAMP</span>,
    total_spend <span class="syntax-highlight">DECIMAL</span>(<span class="syntax-highlight">10</span>,<span class="syntax-highlight">2</span>),
    region <span class="syntax-highlight">VARCHAR</span>(<span class="syntax-highlight">50</span>),
    <span class="syntax-comment">-- Additional columns as needed</span>
    load_timestamp <span class="syntax-highlight">TIMESTAMP</span> <span class="syntax-keyword">DEFAULT</span> CURRENT_TIMESTAMP
);

<span class="syntax-comment">-- Load data from CSV</span>
<span class="syntax-keyword">COPY</span> staging.raw_data (customer_id, customer_name, email, signup_date, last_purchase, total_spend, region)
<span class="syntax-keyword">FROM</span> <span class="syntax-string">'/path/to/input_data.csv'</span>
<span class="syntax-keyword">WITH</span> (
    FORMAT csv,
    HEADER <span class="syntax-keyword">true</span>,
    DELIMITER <span class="syntax-string">','</span>,
    NULL <span class="syntax-string">'NULL'</span>
);

<span class="syntax-comment">-- Create processed data table</span>
<span class="syntax-keyword">CREATE</span> <span class="syntax-keyword">TABLE</span> IF <span class="syntax-keyword">NOT</span> <span class="syntax-keyword">EXISTS</span> analytics.customers (
    customer_id <span class="syntax-highlight">INT</span> <span class="syntax-keyword">PRIMARY</span> <span class="syntax-keyword">KEY</span>,
    customer_name <span class="syntax-highlight">VARCHAR</span>(<span class="syntax-highlight">100</span>) <span class="syntax-keyword">NOT</span> <span class="syntax-keyword">NULL</span>,
    email <span class="syntax-highlight">VARCHAR</span>(<span class="syntax-highlight">255</span>) <span class="syntax-keyword">UNIQUE</span>,
    signup_date <span class="syntax-highlight">DATE</span>,
    days_since_signup <span class="syntax-highlight">INT</span>,
    last_purchase <span class="syntax-highlight">TIMESTAMP</span>,
    days_since_purchase <span class="syntax-highlight">INT</span>,
    total_spend <span class="syntax-highlight">DECIMAL</span>(<span class="syntax-highlight">10</span>,<span class="syntax-highlight">2</span>),
    spend_category <span class="syntax-highlight">VARCHAR</span>(<span class="syntax-highlight">20</span>),
    region <span class="syntax-highlight">VARCHAR</span>(<span class="syntax-highlight">50</span>),
    is_active <span class="syntax-highlight">BOOLEAN</span>,
    processing_date <span class="syntax-highlight">DATE</span> <span class="syntax-keyword">DEFAULT</span> CURRENT_DATE
);

<span class="syntax-comment">-- Transform and load data</span>
<span class="syntax-keyword">INSERT</span> <span class="syntax-keyword">INTO</span> analytics.customers (
    customer_id, customer_name, email, signup_date, days_since_signup,
    last_purchase, days_since_purchase, total_spend, spend_category,
    region, is_active
)
<span class="syntax-keyword">SELECT</span>
    r.customer_id,
    INITCAP(TRIM(r.customer_name)) <span class="syntax-keyword">AS</span> customer_name,
    LOWER(TRIM(r.email)) <span class="syntax-keyword">AS</span> email,
    r.signup_date,
    CURRENT_DATE - r.signup_date <span class="syntax-keyword">AS</span> days_since_signup,
    r.last_purchase,
    CURRENT_DATE - DATE(r.last_purchase) <span class="syntax-keyword">AS</span> days_since_purchase,
    COALESCE(r.total_spend, <span class="syntax-highlight">0</span>) <span class="syntax-keyword">AS</span> total_spend,
    <span class="syntax-keyword">CASE</span>
        <span class="syntax-keyword">WHEN</span> r.total_spend <span class="syntax-keyword">IS</span> <span class="syntax-keyword">NULL</span> <span class="syntax-keyword">THEN</span> <span class="syntax-string">'No Purchases'</span>
        <span class="syntax-keyword">WHEN</span> r.total_spend &lt; <span class="syntax-highlight">100</span> <span class="syntax-keyword">THEN</span> <span class="syntax-string">'Low'</span>
        <span class="syntax-keyword">WHEN</span> r.total_spend &lt; <span class="syntax-highlight">500</span> <span class="syntax-keyword">THEN</span> <span class="syntax-string">'Medium'</span>
        <span class="syntax-keyword">ELSE</span> <span class="syntax-string">'High'</span>
    <span class="syntax-keyword">END</span> <span class="syntax-keyword">AS</span> spend_category,
    r.region,
    (r.last_purchase &gt;= CURRENT_DATE - INTERVAL <span class="syntax-string">'180 days'</span>) <span class="syntax-keyword">AS</span> is_active
<span class="syntax-keyword">FROM</span> staging.raw_data r
<span class="syntax-keyword">WHERE</span> r.customer_id <span class="syntax-keyword">IS</span> <span class="syntax-keyword">NOT</span> <span class="syntax-keyword">NULL</span>
<span class="syntax-keyword">ON</span> CONFLICT (customer_id) <span class="syntax-keyword">DO</span> <span class="syntax-keyword">UPDATE</span>
<span class="syntax-keyword">SET</span>
    customer_name = EXCLUDED.customer_name,
    email = EXCLUDED.email,
    last_purchase = EXCLUDED.last_purchase,
    total_spend = EXCLUDED.total_spend,
    spend_category = EXCLUDED.spend_category,
    is_active = EXCLUDED.is_active,
    processing_date = CURRENT_DATE;

<span class="syntax-comment">-- Clean up staging</span>
<span class="syntax-keyword">TRUNCATE</span> <span class="syntax-keyword">TABLE</span> staging.raw_data;</code></pre>
                    </div>

                    <div class="grid">
                        <div class="card">
                            <h3>Database Specifics</h3>
                            <p>• PostgreSQL syntax shown</p>
                            <p>• Compatible with Snowflake, Redshift</p>
                            <p>• Adjust for MySQL/SQL Server as needed</p>
                        </div>
                        <div class="card">
                            <h3>Performance</h3>
                            <p>• Add appropriate indexes</p>
                            <p>• Consider partitioning large tables</p>
                            <p>• Use bulk operations where possible</p>
                        </div>
                        <div class="card">
                            <h3>Extensions</h3>
                            <p>• Add error logging</p>
                            <p>• Implement CDC patterns</p>
                            <p>• Add data quality checks</p>
                        </div>
                    </div>
                </div>

                <div id="scala" class="tab-content">
                    <div class="code-container">
                        <div class="code-header">
                            <span>Scala ETL Pipeline</span>
                            <button class="copy-btn" onclick="copyCode('scala-code')">
                                <i class="fas fa-copy"></i> Copy
                            </button>
                        </div>
                        <pre id="scala-code" class="code-content"><code><span class="syntax-keyword">import</span> org.apache.spark.sql.{SparkSession, DataFrame}
<span class="syntax-keyword">import</span> org.apache.spark.sql.functions._
<span class="syntax-keyword">import</span> org.apache.spark.sql.types._
<span class="syntax-keyword">import</span> java.time.LocalDateTime

<span class="syntax-keyword">object</span> ETLPipeline {
  
  <span class="syntax-keyword">def</span> <span class="syntax-function">main</span>(args: Array[String]): Unit = {
    
    <span class="syntax-comment">// Initialize Spark</span>
    <span class="syntax-keyword">val</span> spark = SparkSession.builder()
      .appName(<span class="syntax-string">"ScalaETLPipeline"</span>)
      .config(<span class="syntax-string">"spark.sql.shuffle.partitions"</span>, <span class="syntax-string">"8"</span>)
      .getOrCreate()
      
    <span class="syntax-keyword">import</span> spark.implicits._
    
    <span class="syntax-keyword">try</span> {
      <span class="syntax-comment">// Configuration</span>
      <span class="syntax-keyword">val</span> inputPath = <span class="syntax-string">"hdfs://path/to/input/data"</span>
      <span class="syntax-keyword">val</span> outputPath = <span class="syntax-string">"hdfs://path/to/output/data"</span>
      
      <span class="syntax-comment">// Load data</span>
      <span class="syntax-keyword">val</span> rawDF = loadData(spark, inputPath)
      
      <span class="syntax-comment">// Transform data</span>
      <span class="syntax-keyword">val</span> processedDF = transformData(rawDF)
      
      <span class="syntax-comment">// Write output</span>
      processedDF.write
        .mode(<span class="syntax-string">"overwrite"</span>)
        .parquet(outputPath)
        
      println(<span class="syntax-string">s"Successfully processed ${processedDF.count()} records"</span>)
      
    } <span class="syntax-keyword">catch</span> {
      <span class="syntax-keyword">case</span> e: Exception =&gt;
        println(<span class="syntax-string">s"ETL failed: ${e.getMessage}"</span>)
        System.exit(<span class="syntax-highlight">1</span>)
    } <span class="syntax-keyword">finally</span> {
      spark.stop()
    }
  }
  
  <span class="syntax-keyword">def</span> <span class="syntax-function">loadData</span>(spark: SparkSession, path: String): DataFrame = {
    <span class="syntax-keyword">try</span> {
      <span class="syntax-keyword">val</span> df = spark.read
        .option(<span class="syntax-string">"header"</span>, <span class="syntax-string">"true"</span>)
        .option(<span class="syntax-string">"inferSchema"</span>, <span class="syntax-string">"true"</span>)
        .csv(path)
        
      <span class="syntax-keyword">if</span> (df.isEmpty) {
        <span class="syntax-keyword">throw</span> <span class="syntax-keyword">new</span> RuntimeException(<span class="syntax-string">"Empty dataframe loaded"</span>)
      }
      
      df
    } <span class="syntax-keyword">catch</span> {
      <span class="syntax-keyword">case</span> e: Exception =&gt;
        println(<span class="syntax-string">s"Error loading data: ${e.getMessage}"</span>)
        <span class="syntax-keyword">throw</span> e
    }
  }
  
  <span class="syntax-keyword">def</span> <span class="syntax-function">transformData</span>(df: DataFrame): DataFrame = {
    <span class="syntax-comment">// Clean column names</span>
    <span class="syntax-keyword">val</span> cleanDF = df.columns.foldLeft(df) { (tempDF, colName) =&gt;
      tempDF.withColumnRenamed(colName, colName.toLowerCase().replace(<span class="syntax-string">" "</span>, <span class="syntax-string">"_"</span>))
    }
    
    <span class="syntax-comment">// Handle missing values</span>
    <span class="syntax-keyword">val</span> filledDF = cleanDF.na.fill(Map(
      <span class="syntax-string">"numeric_columns"</span> -&gt; <span class="syntax-highlight">0</span>,
      <span class="syntax-string">"string_columns"</span> -&gt; <span class="syntax-string">"Unknown"</span>,
      <span class="syntax-string">"date_columns"</span> -&gt; current_date()
    ))
    
    <span class="syntax-comment">// Standardize text columns</span>
    <span class="syntax-keyword">val</span> textCols = filledDF.schema.fields
      .filter(_.dataType == StringType)
      .map(_.name)
      
    <span class="syntax-keyword">val</span> standardizedDF = textCols.foldLeft(filledDF) { (tempDF, colName) =&gt;
      tempDF.withColumn(colName, trim(initcap(col(colName))))
    }
    
    <span class="syntax-comment">// Add processing metadata</span>
    standardizedDF.withColumn(<span class="syntax-string">"processing_timestamp"</span>, current_timestamp())
  }
}</code></pre>
                    </div>

                    <div class="grid">
                        <div class="card">
                            <h3>Scala Benefits</h3>
                            <p>• Type safety at compile time</p>
                            <p>• Better performance than Python</p>
                            <p>• Native Spark integration</p>
                        </div>
                        <div class="card">
                            <h3>Best Practices</h3>
                            <p>• Use case classes for schemas</p>
                            <p>• Implement proper error handling</p>
                            <p>• Use functional programming patterns</p>
                        </div>
                        <div class="card">
                            <h3>Extensions</h3>
                            <p>• Add unit tests with ScalaTest</p>
                            <p>• Implement custom UDFs</p>
                            <p>• Add monitoring metrics</p>
                        </div>
                    </div>
                </div>

                <div style="text-align: center; margin-top: 24px;">
                    <button class="btn btn-primary" onclick="generateNewCode()">
                        <i class="fas fa-sync-alt"></i> Regenerate Code with Different Approach
                    </button>
                    <button class="btn btn-secondary" style="margin-left: 12px;" onclick="customizeCode()">
                        <i class="fas fa-cog"></i> Customize Parameters
                    </button>
                </div>
            </div>
        </div>
    </div>

    <script>
        // Set active tab
        function setActiveTab(tabElement, tabId) {
            document.querySelectorAll('.tab').forEach(tab => tab.classList.remove('active'));
            document.querySelectorAll('.tab-content').forEach(content => content.classList.remove('active'));
            
            tabElement.classList.add('active');
            document.getElementById(tabId).classList.add('active');
        }

        // Copy code to clipboard
        function copyCode(elementId) {
            const codeElement = document.getElementById(elementId);
            const range = document.createRange();
            range.selectNode(codeElement);
            window.getSelection().removeAllRanges();
            window.getSelection().addRange(range);
            document.execCommand('copy');
            window.getSelection().removeAllRanges();
            
            // Show copied notification
            const btn = event.target.closest('.copy-btn');
            btn.innerHTML = '<i class="fas fa-check"></i> Copied!';
            setTimeout(() => {
                btn.innerHTML = '<i class="fas fa-copy"></i> Copy';
            }, 2000);
        }

        // Simulate code generation
        function generateNewCode() {
            const activeTab = document.querySelector('.tab.active').id;
            const btn = event.target.closest('button');
            const originalText = btn.innerHTML;
            
            btn.innerHTML = '<span class="loading-spinner"></span> Generating...';
            btn.disabled = true;
            
            // Simulate API call delay
            setTimeout(() => {
                // In a real implementation, this would call an LLM API
                // and update the code content with the response
                
                // For demo, we'll just rotate through some variations
                const variations = {
                    python: [
                        `# Alternative Python approach using polars\nimport polars as pl\n\ndef load_data(path):\n    return pl.read_csv(path)\n\n# ... rest of the code ...`,
                        `# Python ETL with more detailed error handling\nimport pandas as pd\nfrom datetime import datetime\nimport logging\n\n# Set up logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# ... rest of the code ...`
                    ],
                    pyspark: [
                        `# PySpark with Delta Lake\nfrom delta.tables import *\n\n# Initialize Spark with Delta\nspark = SparkSession.builder \\\n    .appName("DeltaETL") \\\n    .config("spark.sql.extensions", "io.delta.sql.DeltaSparkSessionExtension") \\\n    .config("spark.sql.catalog.spark_catalog", "org.apache.spark.sql.delta.catalog.DeltaCatalog") \\\n    .getOrCreate()\n\n# ... rest of the code ...`,
                        `# PySpark with optimized configurations\nspark = SparkSession.builder \\\n    .appName("OptimizedETL") \\\n    .config("spark.sql.shuffle.partitions", "16") \\\n    .config("spark.executor.memory", "8g") \\\n    .getOrCreate()\n\n# ... rest of the code ...`
                    ],
                    sql: [
                        `-- SQL with more advanced transformations\nWITH cleaned_data AS (\n    SELECT \n        customer_id,\n        REGEXP_REPLACE(customer_name, '[^a-zA-Z ]', '') AS customer_name,\n        -- ... other transformations\n    FROM staging.raw_data\n)\n-- ... rest of the query ...`,
                        `-- SQL with partitioning and optimization hints\n/*+ OPTIMIZER_FEATURES_ENABLE('12.2') */\nINSERT /*+ APPEND */ INTO analytics.customers\n-- ... rest of the query ...`
                    ],
                    scala: [
                        `// Scala with Cats Effect for resource management\nimport cats.effect.IO\nimport cats.effect.unsafe.implicits.global\n\nobject ETLPipeline extends App {\n  // ... rest of the code ...`,
                        `// Scala with ZIO for functional effects\nimport zio._\nimport zio.spark._\n\nobject ETLPipeline extends ZIOAppDefault {\n  // ... rest of the code ...`
                    ]
                };
                
                const currentVariations = variations[activeTab] || [];
                if (currentVariations.length > 0) {
                    const randomIndex = Math.floor(Math.random() * currentVariations.length);
                    const codeContent = document.getElementById(`${activeTab}-code`).querySelector('code');
                    codeContent.innerHTML = currentVariations[randomIndex] + codeContent.innerHTML.split('\n').slice(10).join('\n');
                }
                
                btn.innerHTML = originalText;
                btn.disabled = false;
                
                // Show notification
                showNotification('Success', 'New code generated with alternative approach', 'success');
            }, 1500);
        }

        // Customize code parameters
        function customizeCode() {
            // In a real implementation, this would open a modal with customization options
            showNotification('Info', 'Customization options would be shown here', 'info');
        }

        // Show notification
        function showNotification(title, message, type) {
            const notification = document.createElement('div');
            notification.className = `notification ${type}`;
            notification.innerHTML = `
                <div class="notification-icon notification-icon-${type}">
                    <i class="fas fa-${type === 'success' ? 'check' : type === 'error' ? 'exclamation' : type === 'warning' ? 'exclamation-triangle' : 'info'}"></i>
                </div>
                <div class="notification-content">
                    <div class="notification-title">${title}</div>
                    <div class="notification-message">${message}</div>
                </div>
                <div class="notification-close" onclick="this.parentElement.remove()">
                    <i class="fas fa-times"></i>
                </div>
            `;
            
            document.body.appendChild(notification);
            setTimeout(() => {
                notification.style.transform = 'translateY(0)';
                notification.style.opacity = '1';
            }, 10);
            
            setTimeout(() => {
                notification.style.transform = 'translateY(20px)';
                notification.style.opacity = '0';
                setTimeout(() => notification.remove(), 300);
            }, 5000);
        }

        // Initialize the page
        document.addEventListener('DOMContentLoaded', function() {
            // Simulate loading data from parent window
            setTimeout(() => {
                // In a real implementation, this would receive the actual data structure
                showNotification('Data Loaded', 'Analyzed dataset structure and generated optimized ETL code', 'success');
            }, 500);
        });
    </script>
</body>
</html>